---
layout: post
title: android通讯(一)binder
category: android
keywords: android,binder,通讯
---


# 0x01.C/S通讯架构

在android基于binder的c/s架构中,除了client和server端之外还有一个manager端,它主要用来管理c/s架构,如图所示
    
![1](http://7xkw0v.com1.z0.glb.clouddn.com/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202016-02-06%20%E4%B8%8B%E5%8D%881.54.38.png)    
    
当然android中很多其他程序他可能会直接使用pipe通信或者,socket通信,就不需要使用binder进行通讯手段


# 0x02.MediaServer解析


## 0x021.注册服务

MediaServer(frameworks/base/media/mediaserver/main_mediaserver.cpp)的入口,他是一个可执行程序

![1](http://7xkw0v.com1.z0.glb.clouddn.com/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202016-02-06%20%E4%B8%8B%E5%8D%882.14.32.png)


**步骤一:获得ProcessState即实际的通信接口**
	
其中ProcessState（frameworks/base/libs/binder/ProcessState.cpp）这个对象,他是单例的,即进程共享的
![1](http://7xkw0v.com1.z0.glb.clouddn.com/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202016-02-06%20%E4%B8%8B%E5%8D%882.25.15.png)

ProcessState的初始化:

![1](http://7xkw0v.com1.z0.glb.clouddn.com/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202016-02-06%20%E4%B8%8B%E5%8D%882.27.54.png)

可以看出其底层还是用mmap进行通信,只是封装成不同的api

mmap的驱动文件是mDriverFD,open_driver函数打开了/dev/binder文件的函数并且返回了fd

**步骤二:生产出BpBinder**

再看defaultServiceManager

![1](http://7xkw0v.com1.z0.glb.clouddn.com/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202016-02-06%20%E4%B8%8B%E5%8D%887.12.44.png)

又是个单例,看下ProcessState::self()->getContextObject(NULL)的调用

![1](http://7xkw0v.com1.z0.glb.clouddn.com/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202016-02-06%20%E4%B8%8B%E5%8D%887.37.52.png)

重定向到了getStrongProxyForHandle
![1](http://7xkw0v.com1.z0.glb.clouddn.com/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202016-02-06%20%E4%B8%8B%E5%8D%887.42.46.png)

注意到这里的handle传入的是0，handle一般用来表示某一类资源的集合,句柄,传入0则代表新创建,这时一层层返回,返回的对象为BpBinder

![1](http://7xkw0v.com1.z0.glb.clouddn.com/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202016-02-06%20%E4%B8%8B%E5%8D%887.47.31.png)

BpBinder和BBinder都是IBinder接口衍生出来的子类
> * BpBinder是客户端用来与Server交互的代理类,
> * BBinder是相对的另一端,他是BpBinder交互的目的端,且一一对应

**步骤三:BpBinder生产出BpServiceManager**

回到defaultServiceManager中,可以看到BpBinder被强制转型了

![1](http://7xkw0v.com1.z0.glb.clouddn.com/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202016-02-06%20%E4%B8%8B%E5%8D%888.12.50.png)

看下interface_cast

![1](http://7xkw0v.com1.z0.glb.clouddn.com/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202016-02-06%20%E4%B8%8B%E5%8D%888.18.25.png)

发现asInterface并不在IServerManager里面,

原来是其定义的一个宏DECLARE_META_INTERFACE(ServiceManager); 在IServiceManager.h中

![1](http://7xkw0v.com1.z0.glb.clouddn.com/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202016-02-06%20%E4%B8%8B%E5%8D%888.32.15.png)

原来是宏函数,替换成这样

![1](http://7xkw0v.com1.z0.glb.clouddn.com/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202016-02-06%20%E4%B8%8B%E5%8D%888.38.42.png)

正好在IServiceManager.cpp也有一个实现的宏IMPLEMENT_META_INTERFACE(ServiceManager,"android.os.IServiceManager");

![1](http://7xkw0v.com1.z0.glb.clouddn.com/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202016-02-06%20%E4%B8%8B%E5%8D%888.43.07.png)

宏替换

![1](http://7xkw0v.com1.z0.glb.clouddn.com/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202016-02-06%20%E4%B8%8B%E5%8D%888.50.56.png)

饶了一圈终于看到了asInterface的真面目

实际调用书上说是intr=new BpServiceManager(obj); 这一行

其用BpBinder(0)构建了一个BpServiceManager.

那么这个BpServiceManager是什么呢,可以看看IServiceManager家族

![1](http://7xkw0v.com1.z0.glb.clouddn.com/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202016-02-06%20%E4%B8%8B%E5%8D%889.02.30.png)

> * IServiceManager、BpServiceManager和BnServiceManager都是和业务逻辑相关
> * BnServiceManager同时从IServiceManager派生,但表示可以直接参与Binder通信,但是他是一个虚类,需要子类来实现
> * BpServiceManager从BpInterface中派生,但这条分支似乎和BpBinder无关系,还是需要靠传入的BpBinder

那么继续跟着看BpServiceManager(frameworks/base/libs/binder/IServiceManager.cpp)的代码

![1](http://7xkw0v.com1.z0.glb.clouddn.com/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202016-02-06%20%E4%B8%8B%E5%8D%889.16.22.png)

BpInterface(frameworks/base/include/binder/IInterface.h)的调用

![1](http://7xkw0v.com1.z0.glb.clouddn.com/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202016-02-06%20%E4%B8%8B%E5%8D%889.18.19.png)

BpRefBase(frameworks/base/libs/binder/Binder.cpp)的调用

![1](http://7xkw0v.com1.z0.glb.clouddn.com/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202016-02-06%20%E4%B8%8B%E5%8D%889.22.13.png)

其中BpServiceManager父类中的BpRefBase中的mRemote属性指向了BpBinder

**步骤四:BpServiceManager服务注册到ServerManager**

回到main函数,MediaPlayerService::instantiate();

![1](http://7xkw0v.com1.z0.glb.clouddn.com/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202016-02-07%20%E4%B8%8A%E5%8D%8811.43.10.png)

IServiceManager.cpp::BpServiceManager(frameworks/base/libs/binder/IServiceManager.cpp)

![1](http://7xkw0v.com1.z0.glb.clouddn.com/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202016-02-14%20%E4%B8%8A%E5%8D%8811.51.34.png)

看到可以remote()函数(这个函数是Binder.h中提供)

![1](http://7xkw0v.com1.z0.glb.clouddn.com/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202016-02-14%20%E4%B8%8B%E5%8D%8812.17.57.png)

返回的是binder中的mRemote对象,而上文中已经提到mRemote属性实际指向了BpBinder

**步骤五:IPCThreadState实际通讯过程**

再调用了BpBinder的transact方法

![1](http://7xkw0v.com1.z0.glb.clouddn.com/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202016-02-14%20%E4%B8%8B%E5%8D%8812.19.53.png)

注意到这里用到了IPCThreadState,那么他是用来做什么的

![1](http://7xkw0v.com1.z0.glb.clouddn.com/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202016-02-14%20%E4%B8%8B%E5%8D%8812.27.01.png)

这里有个主要的函数pthread_getpecific,这是unix的函数,关于这个函数,可以参考[ pthread_getspecific和pthread_setspecific使用](http://blog.csdn.net/lwfcgz/article/details/37570667)这篇文章

构造

![1](http://7xkw0v.com1.z0.glb.clouddn.com/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202016-02-14%20%E4%B8%8B%E5%8D%8812.29.28.png)

通过构造可以看出来,IPCThreadState是每个线程独有的,类似于ThreadLocal的保存方式


之后调用了IPCThreadState的transact

![1](http://7xkw0v.com1.z0.glb.clouddn.com/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202016-02-14%20%E4%B8%8B%E5%8D%8812.32.43.png)

这个函数才是实际上完成了binder通讯工作的函数

期间主要的函数为writeTransactionData和waitForResponse

writeTransactionData是直接把原先传过来的数据进行封装,然后写入

而waitForResponse是用来检查错误,已经获取返回数据的(一般写入之后都会有返回),waitForResponse在正常情况下会去调用executeCommand否则报错

![1](http://7xkw0v.com1.z0.glb.clouddn.com/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202016-02-14%20%E4%B8%8B%E5%8D%882.18.51.png)

executeCommand函数中

![1](http://7xkw0v.com1.z0.glb.clouddn.com/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202016-02-14%20%E4%B8%8B%E5%8D%881.00.59.png)

实际上在waitForResponse中调用的talkwithDriver完成了通讯的过程.实际工作为**ioctl**来读写,将读写的数据放在mIn,mOut之中.


**步骤五:进行服务**

![1](http://7xkw0v.com1.z0.glb.clouddn.com/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202016-02-14%20%E4%B8%8B%E5%8D%882.21.50.png)

上文我们以及分析过ProcessState了,但实际在上文中并没有用到它,而这里获取的ProcessState实际上是当前进程的单例

接着看startThreadPool函数

![1](http://7xkw0v.com1.z0.glb.clouddn.com/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202016-02-14%20%E4%B8%8B%E5%8D%882.25.36.png)

![1](http://7xkw0v.com1.z0.glb.clouddn.com/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202016-02-14%20%E4%B8%8B%E5%8D%882.26.55.png)

startThreadPool其实是创建一个thread,创建完之后也同时调用了joinThreadPool方法

![1](http://7xkw0v.com1.z0.glb.clouddn.com/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202016-03-20%20%E4%B8%8B%E5%8D%888.48.26.png)

joinThreadPool方法

![1](http://7xkw0v.com1.z0.glb.clouddn.com/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202016-03-20%20%E4%B8%8B%E5%8D%888.53.02.png)

两个线程在不断地等待请求服务


# 0x03.简短总结

不得不说,binder这个东西实在是复杂难懂.这专题看了好几遍才有个大致的理解,原来之前一直理解错了.


## 0x031.注册服务

注册代码如下:

```
    sp<ProcessState> proc(ProcessState::self());
    sp<IServiceManager> sm = defaultServiceManager();
    MediaPlayerService::instantiate();
    ProcessState::self()->startThreadPool();
    IPCThreadState::self()->joinThreadPool();
```


过程如下:
> * **初始化一个ProcessState**,ProcessState这个东西主要用来创建和ServiceManager的联系,以及线程池
> * **通过ProcessState创建BpBinder**(BpBinder为用户空间的客户端专有的通信对象),在创建的同时BpBinder的内核空间的对应对象就已经创建好了,**同时BpBinder指向的句柄handle是0的,表示的是其指向的ServiceMannager的BBinder**,ServiceMannager是在init进程创建它的时候就已经创建好了BBinder和内核空间的binder_node.
> * BpBinder对象可以大致的理解成,在用户控件去操控Binder驱动的对象,其是可以执行对Binder驱动WR操作(其实并不是,还有一个内部封装的对象IPCThreadState),而之后再defaultServiceManager方法中**BpBinder会被用作装饰器模式被封装成IServiceManager的一个子类BpServiceManager,很明显他是一个装饰器模式(我理解成装饰器模式的设计)**.其装饰的过程是用到了interface_cast<IServiceManager>这个东西,这个模板很方便的转化了BpBinder到BpServiceManager.
> * **BpServiceManager调用addservice将service注册到了ServiceManager**,实际上其封装了一个IPCThreadState类来进行binder的交互.这个类是线程独立的,所以之后可以创建多线程去处理ipc请求.每个IPCThreadState中都有一个mIn和mOut是Parcel对象,用来和binder交互(实际工作为ioctl来读写,将读写的数据放在mIn,mOut之中)
> * 之后**startThreadPool()创建一个新线程,其内的方法也是调用joinThreadPool(),joinThreadPool这个方法就是用来服务Binder的server**,所以有两个线程在进行当前binder的监听状态.不断地等待有client来连接他们



# 0x03.结尾

感谢邓老师的书《深入理解android》

后续将分析SystemManager、java-binder、aosp中三种常用的进程通讯方式、内核中的binder实现原理




